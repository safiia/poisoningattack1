{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The notebook contains\n",
    "### Code for _Bulyan_ aggregation algorithm\n",
    "### Evaluation of all the attacks (Fang, LIE, and our AGR-agnstic) on Multi-krum, except our AGR-tailored attack on Bulyan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse, os, sys, csv, shutil, time, random, operator, pickle, ast, math, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.optim import Optimizer\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import pickle\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "sys.path.insert(0,'./../utils/')\n",
    "from logger import *\n",
    "from eval import *\n",
    "from misc import *\n",
    "\n",
    "from femnist_normal_train import *\n",
    "from femnist_util import *\n",
    "from adam import Adam\n",
    "from sgd import SGD\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the FEMNIST dataset; we use [LEAF framework](https://leaf.cmu.edu/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tr_data = []\n",
    "user_tr_labels = []\n",
    "\n",
    "for i in range(34):\n",
    "    f = './leaf/data/femnist/data/train/all_data_%d_niid_05_keep_0_train_9.json'%i\n",
    "    with open(f, 'r') as myfile:\n",
    "        data=myfile.read()\n",
    "    obj = json.loads(data)\n",
    "    \n",
    "    for user in obj['users']:\n",
    "        user_tr_data.append(obj['user_data'][user]['x'])\n",
    "        user_tr_labels.append(obj['user_data'][user]['y'])\n",
    "\n",
    "user_te_data = []\n",
    "user_te_labels = []\n",
    "\n",
    "for i in range(34):\n",
    "    f = './leaf/data/femnist/data/test/all_data_%d_niid_05_keep_0_test_9.json'%i\n",
    "    with open(f, 'r') as myfile:\n",
    "        data=myfile.read()\n",
    "    obj = json.loads(data)\n",
    "    \n",
    "    for user in obj['users']:\n",
    "        user_te_data.append(obj['user_data'][user]['x'])\n",
    "        user_te_labels.append(obj['user_data'][user]['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user 0 tr len 159\n",
      "user 1 tr len 158\n",
      "user 2 tr len 162\n",
      "user 3 tr len 161\n",
      "user 4 tr len 109\n",
      "user 5 tr len 152\n",
      "user 6 tr len 158\n",
      "user 7 tr len 153\n",
      "user 8 tr len 162\n",
      "user 9 tr len 135\n",
      "user 10 tr len 156\n",
      "user 11 tr len 151\n",
      "user 12 tr len 83\n",
      "user 13 tr len 162\n",
      "user 14 tr len 153\n",
      "user 15 tr len 55\n",
      "user 16 tr len 163\n",
      "user 17 tr len 130\n",
      "user 18 tr len 162\n",
      "user 19 tr len 156\n",
      "user 20 tr len 148\n",
      "user 21 tr len 161\n",
      "user 22 tr len 146\n",
      "user 23 tr len 121\n",
      "user 24 tr len 153\n",
      "user 25 tr len 133\n",
      "user 26 tr len 33\n",
      "user 27 tr len 135\n",
      "user 28 tr len 159\n",
      "user 29 tr len 134\n",
      "user 30 tr len 162\n",
      "user 31 tr len 157\n",
      "user 32 tr len 25\n",
      "user 33 tr len 152\n",
      "user 34 tr len 128\n",
      "user 35 tr len 161\n",
      "user 36 tr len 165\n",
      "user 37 tr len 163\n",
      "user 38 tr len 7\n",
      "user 39 tr len 133\n",
      "user 40 tr len 156\n",
      "user 41 tr len 156\n",
      "user 42 tr len 155\n",
      "user 43 tr len 156\n",
      "user 44 tr len 22\n",
      "user 45 tr len 158\n",
      "user 46 tr len 163\n",
      "user 47 tr len 162\n",
      "user 48 tr len 155\n",
      "user 49 tr len 135\n",
      "user 50 tr len 160\n",
      "user 51 tr len 153\n",
      "user 52 tr len 156\n",
      "user 53 tr len 161\n",
      "user 54 tr len 152\n",
      "user 55 tr len 245\n",
      "user 56 tr len 296\n",
      "user 57 tr len 200\n",
      "user 58 tr len 312\n",
      "user 59 tr len 150\n",
      "user 60 tr len 250\n",
      "user 61 tr len 194\n",
      "user 62 tr len 289\n",
      "user 63 tr len 280\n",
      "user 64 tr len 221\n",
      "user 65 tr len 323\n",
      "user 66 tr len 221\n",
      "user 67 tr len 317\n",
      "user 68 tr len 261\n",
      "user 69 tr len 88\n",
      "user 70 tr len 252\n",
      "user 71 tr len 325\n",
      "user 72 tr len 267\n",
      "user 73 tr len 315\n",
      "user 74 tr len 81\n",
      "user 75 tr len 333\n",
      "user 76 tr len 277\n",
      "user 77 tr len 242\n",
      "user 78 tr len 213\n",
      "user 79 tr len 164\n",
      "user 80 tr len 152\n",
      "user 81 tr len 113\n",
      "user 82 tr len 144\n",
      "user 83 tr len 143\n",
      "user 84 tr len 125\n",
      "user 85 tr len 126\n",
      "user 86 tr len 102\n",
      "user 87 tr len 157\n",
      "user 88 tr len 139\n",
      "user 89 tr len 36\n",
      "user 90 tr len 130\n",
      "user 91 tr len 148\n",
      "user 92 tr len 135\n",
      "user 93 tr len 135\n",
      "user 94 tr len 99\n",
      "user 95 tr len 133\n",
      "user 96 tr len 15\n",
      "user 97 tr len 144\n",
      "user 98 tr len 129\n",
      "user 99 tr len 146\n",
      "user 100 tr len 123\n",
      "user 101 tr len 121\n",
      "user 102 tr len 152\n",
      "user 103 tr len 155\n",
      "user 104 tr len 148\n",
      "user 105 tr len 133\n",
      "user 106 tr len 77\n",
      "user 107 tr len 126\n",
      "user 108 tr len 146\n",
      "user 109 tr len 135\n",
      "user 110 tr len 135\n",
      "user 111 tr len 115\n",
      "user 112 tr len 24\n",
      "user 113 tr len 153\n",
      "user 114 tr len 159\n",
      "user 115 tr len 162\n",
      "user 116 tr len 158\n",
      "user 117 tr len 124\n",
      "user 118 tr len 148\n",
      "user 119 tr len 151\n",
      "user 120 tr len 134\n",
      "user 121 tr len 160\n",
      "user 122 tr len 141\n",
      "user 123 tr len 156\n",
      "user 124 tr len 118\n",
      "user 125 tr len 164\n",
      "user 126 tr len 160\n",
      "user 127 tr len 154\n",
      "user 128 tr len 136\n",
      "user 129 tr len 157\n",
      "user 130 tr len 155\n",
      "user 131 tr len 153\n",
      "user 132 tr len 141\n",
      "user 133 tr len 142\n",
      "user 134 tr len 153\n",
      "user 135 tr len 142\n",
      "user 136 tr len 162\n",
      "user 137 tr len 104\n",
      "user 138 tr len 63\n",
      "user 139 tr len 333\n",
      "user 140 tr len 350\n",
      "user 141 tr len 274\n",
      "user 142 tr len 386\n",
      "user 143 tr len 231\n",
      "user 144 tr len 321\n",
      "user 145 tr len 325\n",
      "user 146 tr len 352\n",
      "user 147 tr len 334\n",
      "user 148 tr len 231\n",
      "user 149 tr len 346\n",
      "user 150 tr len 276\n",
      "user 151 tr len 271\n",
      "user 152 tr len 370\n",
      "user 153 tr len 308\n",
      "user 154 tr len 386\n",
      "user 155 tr len 372\n",
      "user 156 tr len 377\n",
      "user 157 tr len 333\n",
      "user 158 tr len 135\n",
      "user 159 tr len 258\n",
      "user 160 tr len 305\n",
      "user 161 tr len 256\n",
      "user 162 tr len 380\n",
      "user 163 tr len 86\n",
      "user 164 tr len 261\n",
      "user 165 tr len 359\n",
      "user 166 tr len 268\n",
      "user 167 tr len 292\n",
      "user 168 tr len 295\n",
      "user 169 tr len 204\n",
      "user 170 tr len 380\n",
      "user 171 tr len 297\n",
      "user 172 tr len 246\n",
      "user 173 tr len 353\n",
      "user 174 tr len 189\n",
      "user 175 tr len 236\n",
      "user 176 tr len 317\n",
      "user 177 tr len 307\n",
      "user 178 tr len 239\n",
      "user 179 tr len 331\n",
      "user 180 tr len 6\n"
     ]
    }
   ],
   "source": [
    "user_tr_data_tensors=[]\n",
    "user_tr_label_tensors=[]\n",
    "\n",
    "for i in range(len(user_tr_data)):\n",
    "    \n",
    "    user_tr_data_tensor=torch.from_numpy(np.array(user_tr_data[i])).type(torch.FloatTensor)\n",
    "    user_tr_label_tensor=torch.from_numpy(np.array(user_tr_labels[i])).type(torch.LongTensor)\n",
    "\n",
    "    user_tr_data_tensors.append(user_tr_data_tensor)\n",
    "    user_tr_label_tensors.append(user_tr_label_tensor)\n",
    "    \n",
    "    print('user %d tr len %d'%(i,len(user_tr_data_tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_data = np.concatenate(user_te_data, 0)\n",
    "te_labels = np.concatenate(user_te_labels)\n",
    "te_len = len(te_labels)\n",
    "\n",
    "te_data_tensor = torch.from_numpy(te_data[:(te_len//2)]).type(torch.FloatTensor)\n",
    "te_label_tensor = torch.from_numpy(te_labels[:(te_len//2)]).type(torch.LongTensor)\n",
    "\n",
    "val_data_tensor = torch.from_numpy(te_data[(te_len//2):]).type(torch.FloatTensor)\n",
    "val_label_tensor = torch.from_numpy(te_labels[(te_len//2):]).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Bulyan aggregation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bulyan(all_updates, n_attackers):\n",
    "    nusers = all_updates.shape[0]\n",
    "    bulyan_cluster = []\n",
    "    candidate_indices = []\n",
    "    remaining_updates = all_updates\n",
    "    all_indices = np.arange(len(all_updates))\n",
    "\n",
    "    while len(bulyan_cluster) < (nusers - 2 * n_attackers):\n",
    "        distances = []\n",
    "        for update in remaining_updates:\n",
    "            distance = torch.norm((remaining_updates - update), dim=1) ** 2\n",
    "            distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "\n",
    "        distances = torch.sort(distances, dim=1)[0]\n",
    "\n",
    "        scores = torch.sum(distances[:, :len(remaining_updates) - 2 - n_attackers], dim=1)\n",
    "        indices = torch.argsort(scores)[:len(remaining_updates) - 2 - n_attackers]\n",
    "\n",
    "        candidate_indices.append(all_indices[indices[0].cpu().numpy()])\n",
    "        all_indices = np.delete(all_indices, indices[0].cpu().numpy())\n",
    "        bulyan_cluster = remaining_updates[indices[0]][None, :] if not len(bulyan_cluster) else torch.cat((bulyan_cluster, remaining_updates[indices[0]][None, :]), 0)\n",
    "        remaining_updates = torch.cat((remaining_updates[:indices[0]], remaining_updates[indices[0] + 1:]), 0)\n",
    "\n",
    "    # print('dim of bulyan cluster ', bulyan_cluster.shape)\n",
    "\n",
    "    n, d = bulyan_cluster.shape\n",
    "    param_med = torch.median(bulyan_cluster, dim=0)[0]\n",
    "    sort_idx = torch.argsort(torch.abs(bulyan_cluster - param_med), dim=0)\n",
    "    sorted_params = bulyan_cluster[sort_idx, torch.arange(d)[None, :]]\n",
    "\n",
    "    return torch.mean(sorted_params[:n - 2 * n_attackers], dim=0), np.array(candidate_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for Fang attack on Bulyan\n",
    "### Fang attacks on MKrum and Bulyan are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lambda(all_updates, model_re, n_attackers):\n",
    "\n",
    "    distances = []\n",
    "    n_benign, d = all_updates.shape\n",
    "    for update in all_updates:\n",
    "        distance = torch.norm((all_updates - update), dim=1)\n",
    "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "\n",
    "    distances[distances == 0] = 10000\n",
    "    distances = torch.sort(distances, dim=1)[0]\n",
    "    scores = torch.sum(distances[:, :n_benign - 2 - n_attackers], dim=1)\n",
    "    min_score = torch.min(scores)\n",
    "    term_1 = min_score / ((n_benign - n_attackers - 1) * torch.sqrt(torch.Tensor([d]))[0])\n",
    "    max_wre_dist = torch.max(torch.norm((all_updates - model_re), dim=1)) / (torch.sqrt(torch.Tensor([d]))[0])\n",
    "\n",
    "    return (term_1 + max_wre_dist)\n",
    "\n",
    "\n",
    "def get_malicious_updates_fang(all_updates, model_re, deviation, n_attackers):\n",
    "\n",
    "    lamda = compute_lambda(all_updates, model_re, n_attackers)\n",
    "\n",
    "    threshold = 1e-5\n",
    "    mal_update = []\n",
    "\n",
    "    while lamda > threshold:\n",
    "        mal_update = (-lamda * deviation)\n",
    "        mal_updates = torch.stack([mal_update] * n_attackers)\n",
    "        mal_updates = torch.cat((mal_updates, all_updates), 0)\n",
    "\n",
    "        # print(mal_updates.shape, n_attackers)\n",
    "        agg_grads, krum_candidate = multi_krum(mal_updates, n_attackers, multi_k=False)\n",
    "        if krum_candidate < n_attackers:\n",
    "            # print('successful lamda is ', lamda)\n",
    "            return mal_update\n",
    "        else:\n",
    "            mal_update = []\n",
    "\n",
    "        lamda *= 0.5\n",
    "\n",
    "    if not len(mal_update):\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        \n",
    "    return mal_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Initializing global model\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a868475a692c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_tr_data_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_tr_label_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "resume=0\n",
    "nepochs=1500\n",
    "gamma=.1\n",
    "fed_lr=0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.float if torch.cuda.is_available() else torch.float#torch.cuda.is_available()\n",
    "batch_size = 100\n",
    "schedule = [2000]\n",
    "\n",
    "aggregation = 'bulyan'\n",
    "at_type = 'fang'\n",
    "chkpt = './' + aggregation\n",
    "epoch_num = 0\n",
    "\n",
    "at_fractions = [20]\n",
    "\n",
    "for at_fraction in at_fractions:\n",
    "\n",
    "    fed_model = mnist_conv().cuda()\n",
    "    fed_model.apply(weights_init)\n",
    "    optimizer_fed = Adam(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    print('==> Initializing global model')\n",
    "    epoch_num = 0\n",
    "    best_global_acc=0\n",
    "    best_global_te_acc=0\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads = []\n",
    "\n",
    "        round_users = np.random.choice(3400, 60)\n",
    "        n_attacker = max(2, np.sum(round_users < (34*at_fraction)))\n",
    "        if n_attacker > 14:\n",
    "            n_attacker = 14\n",
    "\n",
    "        # print('n_attackers is ', n_attackers)\n",
    "        attacker_count = 0\n",
    "        for i in round_users:\n",
    "            if i < (34*at_fraction) and attacker_count < n_attacker:\n",
    "                attacker_count += 1\n",
    "                continue\n",
    "\n",
    "            inputs = user_tr_data_tensors[i]\n",
    "            print( inputs)\n",
    "            targets = user_tr_label_tensors[i]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer_fed.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None,:] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]),0)    \n",
    "\n",
    "        malicious_grads = user_grads\n",
    "\n",
    "        if n_attacker > 0:\n",
    "            if at_type == 'fang':\n",
    "                agg_grads = torch.mean(malicious_grads, 0)\n",
    "                deviation = torch.sign(agg_grads)\n",
    "                mal_update = get_malicious_updates_fang(malicious_grads, agg_grads, deviation, n_attacker)\n",
    "            \n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "            malicious_grads = torch.cat((mal_updates, user_grads), 0)\n",
    "            \n",
    "        if epoch_num == 0: print('malicious grads shape ', malicious_grads.shape)\n",
    "\n",
    "        if aggregation == 'mean':\n",
    "            agg_grads=torch.mean(malicious_grads,dim=0)\n",
    "            \n",
    "        elif aggregation=='krum' or aggregation=='mkrum':\n",
    "            multi_k = True if aggregation == 'mkrum' else False\n",
    "            if epoch_num == 0: print('multi krum is ', multi_k)\n",
    "            agg_grads, krum_candidate = multi_krum(malicious_grads, n_attacker, multi_k=multi_k, verbose=True)\n",
    "        \n",
    "        elif aggregation == 'bulyan':\n",
    "            agg_grads, krum_candidate = bulyan(malicious_grads, n_attacker)\n",
    "            \n",
    "        start_idx=0\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num % 10 == 0:\n",
    "            print('%s: at %s at_frac %.1f n_at %d n_mal_sel %d e %d fed_model val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, at_fraction, n_attacker, np.sum(krum_candidate < n_attacker), epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our first AGR-agnostic attack - Min-Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_attack_dist(all_updates, model_re, n_attackers, dev_type='unit_vec'):\n",
    "\n",
    "    if dev_type == 'unit_vec':\n",
    "        deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "    elif dev_type == 'sign':\n",
    "        deviation = torch.sign(model_re)\n",
    "    elif dev_type == 'std':\n",
    "        deviation = torch.std(all_updates, 0)\n",
    "\n",
    "    lamda = torch.Tensor([50.0]).float().cuda()\n",
    "    # print(lamda)\n",
    "    threshold_diff = 1e-5\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "    \n",
    "    distances = []\n",
    "    for update in all_updates:\n",
    "        distance = torch.norm((all_updates - update), dim=1) ** 2\n",
    "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "    \n",
    "    max_distance = torch.max(distances)\n",
    "    del distances\n",
    "\n",
    "    while torch.abs(lamda_succ - lamda) > threshold_diff:\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        distance = torch.norm((all_updates - mal_update), dim=1) ** 2\n",
    "        max_d = torch.max(distance)\n",
    "        \n",
    "        if max_d <= max_distance:\n",
    "            # print('successful lamda is ', lamda)\n",
    "            lamda_succ = lamda\n",
    "            lamda = lamda + lamda_fail / 2\n",
    "        else:\n",
    "            lamda = lamda - lamda_fail / 2\n",
    "\n",
    "        lamda_fail = lamda_fail / 2\n",
    "\n",
    "    mal_update = (model_re - lamda_succ * deviation)\n",
    "    \n",
    "    return mal_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Initializing global model\n",
      "malicious grads shape  torch.Size([60, 848382])\n",
      "bulyan: at min-max at_frac 20.0 n_at 11 n_mal_sel 4 e 0 fed_model val loss 3.9545 val acc 3.9642 best val_acc 3.964168 te_acc 4.437809\n",
      "bulyan: at min-max at_frac 20.0 n_at 8 n_mal_sel 3 e 10 fed_model val loss 3.8240 val acc 8.8962 best val_acc 10.502471 te_acc 11.395696\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 20 fed_model val loss 3.8531 val acc 13.1770 best val_acc 17.645696 te_acc 19.666392\n",
      "bulyan: at min-max at_frac 20.0 n_at 10 n_mal_sel 4 e 30 fed_model val loss 3.8279 val acc 26.9924 best val_acc 26.992381 te_acc 30.246087\n",
      "bulyan: at min-max at_frac 20.0 n_at 11 n_mal_sel 3 e 40 fed_model val loss 3.6456 val acc 29.0157 best val_acc 30.032434 te_acc 33.991454\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 3 e 50 fed_model val loss 3.2941 val acc 34.1227 best val_acc 34.122735 te_acc 38.279963\n",
      "bulyan: at min-max at_frac 20.0 n_at 11 n_mal_sel 3 e 60 fed_model val loss 3.1105 val acc 31.9862 best val_acc 34.122735 te_acc 38.279963\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 3 e 70 fed_model val loss 2.8140 val acc 35.1292 best val_acc 35.129222 te_acc 39.600494\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 3 e 80 fed_model val loss 2.6504 val acc 35.7599 best val_acc 36.768946 te_acc 41.281404\n",
      "bulyan: at min-max at_frac 20.0 n_at 11 n_mal_sel 3 e 90 fed_model val loss 2.5376 val acc 37.5335 best val_acc 38.176998 te_acc 42.694605\n",
      "bulyan: at min-max at_frac 20.0 n_at 11 n_mal_sel 3 e 100 fed_model val loss 2.5457 val acc 37.2529 best val_acc 38.823105 te_acc 43.528624\n",
      "bulyan: at min-max at_frac 20.0 n_at 3 n_mal_sel 2 e 110 fed_model val loss 2.6276 val acc 38.1358 best val_acc 40.962212 te_acc 45.325371\n",
      "bulyan: at min-max at_frac 20.0 n_at 8 n_mal_sel 3 e 120 fed_model val loss 2.4051 val acc 41.7525 best val_acc 41.752471 te_acc 45.927718\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 130 fed_model val loss 2.4744 val acc 40.9390 best val_acc 43.420511 te_acc 47.423291\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 140 fed_model val loss 2.3296 val acc 43.7037 best val_acc 43.889003 te_acc 47.987026\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 150 fed_model val loss 2.3834 val acc 42.7281 best val_acc 45.554469 te_acc 49.109349\n",
      "bulyan: at min-max at_frac 20.0 n_at 11 n_mal_sel 3 e 160 fed_model val loss 2.5104 val acc 42.8980 best val_acc 46.326709 te_acc 49.824959\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 4 e 170 fed_model val loss 2.3512 val acc 42.6714 best val_acc 46.957372 te_acc 50.296026\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 180 fed_model val loss 2.3300 val acc 43.0833 best val_acc 46.957372 te_acc 50.296026\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 3 e 190 fed_model val loss 2.2212 val acc 45.8737 best val_acc 46.957372 te_acc 50.296026\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 3 e 200 fed_model val loss 2.1325 val acc 48.2882 best val_acc 48.288200 te_acc 51.758134\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 3 e 210 fed_model val loss 2.1104 val acc 49.8996 best val_acc 50.393843 te_acc 53.539436\n",
      "bulyan: at min-max at_frac 20.0 n_at 10 n_mal_sel 3 e 220 fed_model val loss 2.1932 val acc 49.2664 best val_acc 50.522549 te_acc 53.683587\n",
      "bulyan: at min-max at_frac 20.0 n_at 8 n_mal_sel 3 e 230 fed_model val loss 2.0377 val acc 49.1402 best val_acc 50.522549 te_acc 53.683587\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 4 e 240 fed_model val loss 2.1174 val acc 49.3282 best val_acc 50.522549 te_acc 53.683587\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 250 fed_model val loss 1.9872 val acc 51.3566 best val_acc 51.356569 te_acc 54.507311\n",
      "bulyan: at min-max at_frac 20.0 n_at 11 n_mal_sel 4 e 260 fed_model val loss 1.9634 val acc 52.0258 best val_acc 52.025844 te_acc 54.885708\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 4 e 270 fed_model val loss 1.9777 val acc 50.6384 best val_acc 52.025844 te_acc 54.885708\n",
      "bulyan: at min-max at_frac 20.0 n_at 10 n_mal_sel 4 e 280 fed_model val loss 2.0191 val acc 51.6680 best val_acc 52.139106 te_acc 55.006693\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 290 fed_model val loss 2.0449 val acc 52.7723 best val_acc 52.772343 te_acc 55.377368\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 5 e 300 fed_model val loss 2.0034 val acc 51.2948 best val_acc 52.772343 te_acc 55.377368\n",
      "bulyan: at min-max at_frac 20.0 n_at 10 n_mal_sel 3 e 310 fed_model val loss 1.9987 val acc 51.8096 best val_acc 53.274300 te_acc 56.067236\n",
      "bulyan: at min-max at_frac 20.0 n_at 7 n_mal_sel 3 e 320 fed_model val loss 2.2394 val acc 50.7362 best val_acc 53.274300 te_acc 56.067236\n",
      "bulyan: at min-max at_frac 20.0 n_at 8 n_mal_sel 3 e 330 fed_model val loss 2.2906 val acc 48.3474 best val_acc 53.274300 te_acc 56.067236\n",
      "bulyan: at min-max at_frac 20.0 n_at 10 n_mal_sel 3 e 340 fed_model val loss 2.1061 val acc 51.3514 best val_acc 53.274300 te_acc 56.067236\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 350 fed_model val loss 2.1503 val acc 51.7453 best val_acc 53.608937 te_acc 56.741660\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 6 e 360 fed_model val loss 2.0625 val acc 52.7028 best val_acc 53.681013 te_acc 56.759679\n",
      "bulyan: at min-max at_frac 20.0 n_at 11 n_mal_sel 4 e 370 fed_model val loss 2.4143 val acc 50.8829 best val_acc 54.090301 te_acc 57.215301\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 4 e 380 fed_model val loss 1.9886 val acc 53.5909 best val_acc 54.396623 te_acc 57.055704\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 3 e 390 fed_model val loss 1.9785 val acc 53.1070 best val_acc 55.258958 te_acc 58.239806\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 400 fed_model val loss 2.1292 val acc 52.3708 best val_acc 55.258958 te_acc 58.239806\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 410 fed_model val loss 2.0228 val acc 54.7699 best val_acc 55.258958 te_acc 58.239806\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 420 fed_model val loss 2.0391 val acc 54.7081 best val_acc 55.258958 te_acc 58.239806\n",
      "bulyan: at min-max at_frac 20.0 n_at 11 n_mal_sel 4 e 430 fed_model val loss 2.0234 val acc 54.8574 best val_acc 55.529242 te_acc 58.355643\n",
      "bulyan: at min-max at_frac 20.0 n_at 10 n_mal_sel 4 e 440 fed_model val loss 2.1464 val acc 52.8573 best val_acc 55.529242 te_acc 58.355643\n",
      "bulyan: at min-max at_frac 20.0 n_at 10 n_mal_sel 5 e 450 fed_model val loss 1.9910 val acc 54.7107 best val_acc 55.529242 te_acc 58.355643\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 4 e 460 fed_model val loss 1.9165 val acc 55.0015 best val_acc 55.529242 te_acc 58.355643\n",
      "bulyan: at min-max at_frac 20.0 n_at 11 n_mal_sel 4 e 470 fed_model val loss 1.9377 val acc 55.1431 best val_acc 55.529242 te_acc 58.355643\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 4 e 480 fed_model val loss 2.0734 val acc 54.7879 best val_acc 55.529242 te_acc 58.355643\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 5 e 490 fed_model val loss 1.9988 val acc 55.4881 best val_acc 55.650227 te_acc 58.597611\n",
      "bulyan: at min-max at_frac 20.0 n_at 8 n_mal_sel 3 e 500 fed_model val loss 2.0701 val acc 54.0131 best val_acc 55.650227 te_acc 58.597611\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 4 e 510 fed_model val loss 2.2319 val acc 54.5768 best val_acc 55.789230 te_acc 58.970861\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 5 e 520 fed_model val loss 1.9795 val acc 55.8870 best val_acc 56.064662 te_acc 58.705725\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 530 fed_model val loss 1.9887 val acc 54.6926 best val_acc 56.396726 te_acc 59.210255\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 540 fed_model val loss 1.9668 val acc 55.7043 best val_acc 56.396726 te_acc 59.210255\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 3 e 550 fed_model val loss 2.0579 val acc 54.8883 best val_acc 56.396726 te_acc 59.210255\n",
      "bulyan: at min-max at_frac 20.0 n_at 8 n_mal_sel 3 e 560 fed_model val loss 2.0814 val acc 55.2847 best val_acc 56.396726 te_acc 59.210255\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 570 fed_model val loss 2.1484 val acc 55.5550 best val_acc 56.396726 te_acc 59.210255\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 580 fed_model val loss 1.9083 val acc 56.8652 best val_acc 56.865218 te_acc 59.683896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 5 e 590 fed_model val loss 1.9437 val acc 55.0376 best val_acc 57.745572 te_acc 60.553954\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 5 e 600 fed_model val loss 1.9330 val acc 56.6928 best val_acc 57.745572 te_acc 60.553954\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 610 fed_model val loss 1.9031 val acc 56.3916 best val_acc 57.745572 te_acc 60.553954\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 4 e 620 fed_model val loss 1.9769 val acc 55.6219 best val_acc 57.745572 te_acc 60.553954\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 5 e 630 fed_model val loss 2.1460 val acc 55.3388 best val_acc 57.745572 te_acc 60.553954\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 640 fed_model val loss 2.0416 val acc 56.7674 best val_acc 57.745572 te_acc 60.553954\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 650 fed_model val loss 1.9592 val acc 56.4405 best val_acc 58.157434 te_acc 61.140857\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 660 fed_model val loss 1.9643 val acc 56.2526 best val_acc 58.157434 te_acc 61.140857\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 670 fed_model val loss 1.9334 val acc 57.0557 best val_acc 58.157434 te_acc 61.140857\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 680 fed_model val loss 2.0875 val acc 55.1740 best val_acc 58.157434 te_acc 61.140857\n",
      "bulyan: at min-max at_frac 20.0 n_at 10 n_mal_sel 3 e 690 fed_model val loss 2.1645 val acc 55.5421 best val_acc 58.157434 te_acc 61.140857\n",
      "bulyan: at min-max at_frac 20.0 n_at 11 n_mal_sel 4 e 700 fed_model val loss 1.9510 val acc 56.5229 best val_acc 58.157434 te_acc 61.140857\n",
      "bulyan: at min-max at_frac 20.0 n_at 10 n_mal_sel 4 e 710 fed_model val loss 1.9275 val acc 56.9733 best val_acc 58.157434 te_acc 61.140857\n",
      "bulyan: at min-max at_frac 20.0 n_at 5 n_mal_sel 2 e 720 fed_model val loss 1.8861 val acc 58.1497 best val_acc 58.157434 te_acc 61.140857\n",
      "bulyan: at min-max at_frac 20.0 n_at 10 n_mal_sel 4 e 730 fed_model val loss 1.9123 val acc 56.8601 best val_acc 58.196046 te_acc 61.148579\n",
      "bulyan: at min-max at_frac 20.0 n_at 7 n_mal_sel 3 e 740 fed_model val loss 2.0352 val acc 56.2243 best val_acc 58.564147 te_acc 61.411141\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 750 fed_model val loss 1.9873 val acc 57.9695 best val_acc 58.564147 te_acc 61.411141\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 4 e 760 fed_model val loss 1.9220 val acc 57.2745 best val_acc 58.564147 te_acc 61.411141\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 3 e 770 fed_model val loss 1.9605 val acc 57.9180 best val_acc 58.564147 te_acc 61.411141\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 780 fed_model val loss 1.8728 val acc 57.4701 best val_acc 58.564147 te_acc 61.411141\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 4 e 790 fed_model val loss 1.9975 val acc 57.7868 best val_acc 58.564147 te_acc 61.411141\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 3 e 800 fed_model val loss 1.9747 val acc 58.2063 best val_acc 58.564147 te_acc 61.411141\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 4 e 810 fed_model val loss 1.9954 val acc 55.5601 best val_acc 58.564147 te_acc 61.411141\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 820 fed_model val loss 2.0185 val acc 58.1935 best val_acc 58.564147 te_acc 61.411141\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 830 fed_model val loss 2.0440 val acc 57.8820 best val_acc 58.566722 te_acc 61.483217\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 840 fed_model val loss 1.9287 val acc 58.0030 best val_acc 59.045511 te_acc 61.938839\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 5 e 850 fed_model val loss 2.1851 val acc 56.4508 best val_acc 59.045511 te_acc 61.938839\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 860 fed_model val loss 1.7903 val acc 58.8396 best val_acc 59.369852 te_acc 61.866763\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 3 e 870 fed_model val loss 1.8003 val acc 58.8550 best val_acc 59.851215 te_acc 62.574650\n",
      "bulyan: at min-max at_frac 20.0 n_at 10 n_mal_sel 4 e 880 fed_model val loss 1.9059 val acc 59.2617 best val_acc 60.546231 te_acc 63.295408\n",
      "bulyan: at min-max at_frac 20.0 n_at 10 n_mal_sel 3 e 890 fed_model val loss 1.8698 val acc 59.0507 best val_acc 60.569399 te_acc 63.393225\n",
      "bulyan: at min-max at_frac 20.0 n_at 11 n_mal_sel 4 e 900 fed_model val loss 1.8079 val acc 58.8808 best val_acc 60.569399 te_acc 63.393225\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 910 fed_model val loss 1.7967 val acc 59.3029 best val_acc 60.569399 te_acc 63.393225\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 920 fed_model val loss 1.8078 val acc 59.8744 best val_acc 60.569399 te_acc 63.393225\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 3 e 930 fed_model val loss 1.7644 val acc 60.3429 best val_acc 60.569399 te_acc 63.393225\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 4 e 940 fed_model val loss 1.7547 val acc 60.0005 best val_acc 60.602862 te_acc 63.511635\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 4 e 950 fed_model val loss 1.6822 val acc 60.2142 best val_acc 60.837109 te_acc 63.565692\n",
      "bulyan: at min-max at_frac 20.0 n_at 11 n_mal_sel 3 e 960 fed_model val loss 1.7703 val acc 59.9259 best val_acc 61.220655 te_acc 64.098538\n",
      "bulyan: at min-max at_frac 20.0 n_at 10 n_mal_sel 4 e 970 fed_model val loss 1.6936 val acc 58.6748 best val_acc 61.287582 te_acc 64.178336\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 5 e 980 fed_model val loss 1.8012 val acc 59.7920 best val_acc 61.287582 te_acc 64.178336\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 990 fed_model val loss 1.7216 val acc 60.6363 best val_acc 61.555292 te_acc 64.201503\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 1000 fed_model val loss 1.7501 val acc 59.0069 best val_acc 61.555292 te_acc 64.201503\n",
      "bulyan: at min-max at_frac 20.0 n_at 11 n_mal_sel 4 e 1010 fed_model val loss 1.7488 val acc 60.2373 best val_acc 61.555292 te_acc 64.201503\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 1020 fed_model val loss 1.6732 val acc 60.9529 best val_acc 61.763797 te_acc 64.695737\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 4 e 1030 fed_model val loss 1.6915 val acc 59.8383 best val_acc 61.763797 te_acc 64.695737\n",
      "bulyan: at min-max at_frac 20.0 n_at 11 n_mal_sel 4 e 1040 fed_model val loss 1.7855 val acc 59.8435 best val_acc 61.763797 te_acc 64.695737\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 1050 fed_model val loss 1.8664 val acc 59.3055 best val_acc 61.763797 te_acc 64.695737\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 1060 fed_model val loss 1.8139 val acc 57.9103 best val_acc 61.763797 te_acc 64.695737\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 4 e 1070 fed_model val loss 1.7415 val acc 60.5848 best val_acc 61.802409 te_acc 64.090815\n",
      "bulyan: at min-max at_frac 20.0 n_at 11 n_mal_sel 4 e 1080 fed_model val loss 1.6944 val acc 60.3377 best val_acc 61.802409 te_acc 64.090815\n",
      "bulyan: at min-max at_frac 20.0 n_at 10 n_mal_sel 3 e 1090 fed_model val loss 1.8068 val acc 60.4870 best val_acc 62.731672 te_acc 65.254325\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 5 e 1100 fed_model val loss 1.7556 val acc 61.1228 best val_acc 62.731672 te_acc 65.254325\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 1110 fed_model val loss 1.7028 val acc 60.5668 best val_acc 62.731672 te_acc 65.254325\n",
      "bulyan: at min-max at_frac 20.0 n_at 5 n_mal_sel 2 e 1120 fed_model val loss 1.5966 val acc 61.8307 best val_acc 62.731672 te_acc 65.254325\n",
      "bulyan: at min-max at_frac 20.0 n_at 10 n_mal_sel 3 e 1130 fed_model val loss 1.7233 val acc 61.0096 best val_acc 62.731672 te_acc 65.254325\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 3 e 1140 fed_model val loss 1.7634 val acc 61.5527 best val_acc 62.731672 te_acc 65.254325\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 1150 fed_model val loss 1.6450 val acc 62.2889 best val_acc 62.844934 te_acc 65.272343\n",
      "bulyan: at min-max at_frac 20.0 n_at 10 n_mal_sel 3 e 1160 fed_model val loss 1.6397 val acc 61.1203 best val_acc 62.844934 te_acc 65.272343\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 1170 fed_model val loss 1.7983 val acc 58.5281 best val_acc 62.844934 te_acc 65.272343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 5 e 1180 fed_model val loss 1.6733 val acc 61.9491 best val_acc 62.844934 te_acc 65.272343\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 4 e 1190 fed_model val loss 1.6888 val acc 62.0470 best val_acc 62.844934 te_acc 65.272343\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 1200 fed_model val loss 1.7707 val acc 59.5629 best val_acc 62.844934 te_acc 65.272343\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 3 e 1210 fed_model val loss 1.6172 val acc 62.2941 best val_acc 62.844934 te_acc 65.272343\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 1220 fed_model val loss 1.7081 val acc 60.8757 best val_acc 62.844934 te_acc 65.272343\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 4 e 1230 fed_model val loss 1.6812 val acc 61.8565 best val_acc 62.844934 te_acc 65.272343\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 4 e 1240 fed_model val loss 1.6066 val acc 62.0289 best val_acc 62.844934 te_acc 65.272343\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 3 e 1250 fed_model val loss 1.5897 val acc 61.7921 best val_acc 62.860379 te_acc 65.671334\n",
      "bulyan: at min-max at_frac 20.0 n_at 10 n_mal_sel 3 e 1260 fed_model val loss 1.6126 val acc 61.4781 best val_acc 62.860379 te_acc 65.671334\n",
      "bulyan: at min-max at_frac 20.0 n_at 9 n_mal_sel 3 e 1270 fed_model val loss 1.7096 val acc 62.5335 best val_acc 63.048291 te_acc 65.756281\n",
      "bulyan: at min-max at_frac 20.0 n_at 11 n_mal_sel 4 e 1280 fed_model val loss 1.6177 val acc 62.4331 best val_acc 63.048291 te_acc 65.756281\n",
      "bulyan: at min-max at_frac 20.0 n_at 11 n_mal_sel 4 e 1290 fed_model val loss 1.6259 val acc 62.9273 best val_acc 63.048291 te_acc 65.756281\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 1300 fed_model val loss 1.7164 val acc 60.1138 best val_acc 63.048291 te_acc 65.756281\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 1310 fed_model val loss 1.6419 val acc 61.0868 best val_acc 63.048291 te_acc 65.756281\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 4 e 1320 fed_model val loss 1.7365 val acc 60.8989 best val_acc 63.048291 te_acc 65.756281\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 1330 fed_model val loss 1.6212 val acc 62.2503 best val_acc 63.048291 te_acc 65.756281\n",
      "bulyan: at min-max at_frac 20.0 n_at 8 n_mal_sel 3 e 1340 fed_model val loss 1.6329 val acc 61.6969 best val_acc 63.048291 te_acc 65.756281\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 4 e 1350 fed_model val loss 1.6864 val acc 62.7574 best val_acc 63.048291 te_acc 65.756281\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 3 e 1360 fed_model val loss 1.6793 val acc 62.4923 best val_acc 63.048291 te_acc 65.756281\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 4 e 1370 fed_model val loss 1.6822 val acc 61.4446 best val_acc 63.048291 te_acc 65.756281\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 4 e 1380 fed_model val loss 1.7423 val acc 61.6891 best val_acc 63.048291 te_acc 65.756281\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 1390 fed_model val loss 1.7441 val acc 60.0623 best val_acc 63.048291 te_acc 65.756281\n",
      "bulyan: at min-max at_frac 20.0 n_at 10 n_mal_sel 4 e 1400 fed_model val loss 1.6634 val acc 61.9260 best val_acc 63.048291 te_acc 65.756281\n",
      "bulyan: at min-max at_frac 20.0 n_at 7 n_mal_sel 3 e 1410 fed_model val loss 1.5456 val acc 62.3713 best val_acc 63.048291 te_acc 65.756281\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 3 e 1420 fed_model val loss 1.6126 val acc 62.0289 best val_acc 63.048291 te_acc 65.756281\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 3 e 1430 fed_model val loss 1.5769 val acc 62.7162 best val_acc 63.048291 te_acc 65.756281\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 3 e 1440 fed_model val loss 1.5360 val acc 63.6326 best val_acc 63.632619 te_acc 66.484761\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 3 e 1450 fed_model val loss 1.6245 val acc 62.3172 best val_acc 63.632619 te_acc 66.484761\n",
      "bulyan: at min-max at_frac 20.0 n_at 11 n_mal_sel 3 e 1460 fed_model val loss 1.5403 val acc 62.5592 best val_acc 63.792216 te_acc 66.392092\n",
      "bulyan: at min-max at_frac 20.0 n_at 13 n_mal_sel 4 e 1470 fed_model val loss 1.4984 val acc 62.7909 best val_acc 63.792216 te_acc 66.392092\n",
      "bulyan: at min-max at_frac 20.0 n_at 14 n_mal_sel 4 e 1480 fed_model val loss 1.5168 val acc 63.1821 best val_acc 63.792216 te_acc 66.392092\n",
      "bulyan: at min-max at_frac 20.0 n_at 10 n_mal_sel 3 e 1490 fed_model val loss 1.5278 val acc 62.9711 best val_acc 63.792216 te_acc 66.392092\n",
      "bulyan: at min-max at_frac 20.0 n_at 12 n_mal_sel 3 e 1500 fed_model val loss 1.6212 val acc 62.4073 best val_acc 64.098538 te_acc 67.015033\n"
     ]
    }
   ],
   "source": [
    "resume=0\n",
    "nepochs=1500\n",
    "gamma=.1\n",
    "fed_lr=0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "batch_size = 100\n",
    "schedule = [2000]\n",
    "\n",
    "aggregation = 'bulyan'\n",
    "at_type = 'min-max'\n",
    "chkpt = './' + aggregation\n",
    "epoch_num = 0\n",
    "\n",
    "at_fractions = [20]\n",
    "\n",
    "for at_fraction in at_fractions:\n",
    "\n",
    "    fed_model = mnist_conv().cuda()\n",
    "    fed_model.apply(weights_init)\n",
    "    optimizer_fed = Adam(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    print('==> Initializing global model')\n",
    "    epoch_num = 0\n",
    "    best_global_acc=0\n",
    "    best_global_te_acc=0\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads = []\n",
    "\n",
    "        round_users = np.random.choice(3400, 60)\n",
    "        n_attacker = max(2, np.sum(round_users < (34*at_fraction)))\n",
    "        if n_attacker > 14: n_attacker = 14\n",
    "\n",
    "        attacker_count = 0\n",
    "        for i in round_users:\n",
    "            if i < (34*at_fraction) and attacker_count < n_attacker:\n",
    "                attacker_count += 1\n",
    "                continue\n",
    "\n",
    "            inputs = user_tr_data_tensors[i]\n",
    "            targets = user_tr_label_tensors[i]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer_fed.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None,:] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]),0)    \n",
    "\n",
    "        malicious_grads = user_grads\n",
    "\n",
    "        if n_attacker > 0:\n",
    "            if at_type == 'fang':\n",
    "                agg_grads = torch.mean(malicious_grads, 0)\n",
    "                deviation = torch.sign(agg_grads)\n",
    "                mal_update = get_malicious_updates_fang(malicious_grads, agg_grads, deviation, n_attacker)\n",
    "            elif at_type == 'min-max':\n",
    "                agg_grads = torch.mean(malicious_grads, 0)\n",
    "                mal_update = our_attack_dist(malicious_grads, agg_grads, n_attacker, dev_type='sign')\n",
    "            elif at_type == 'min-sum':\n",
    "                agg_grads = torch.mean(malicious_grads, 0)\n",
    "                mal_update = our_attack_score(malicious_grads, agg_grads, n_attacker, dev_type='sign')\n",
    "                \n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "            malicious_grads = torch.cat((mal_updates, user_grads), 0)\n",
    "            \n",
    "        if epoch_num == 0: print('malicious grads shape ', malicious_grads.shape)\n",
    "\n",
    "        if aggregation == 'mean':\n",
    "            agg_grads=torch.mean(malicious_grads,dim=0)\n",
    "            \n",
    "        elif aggregation=='krum' or aggregation=='mkrum':\n",
    "            multi_k = True if aggregation == 'mkrum' else False\n",
    "            if epoch_num == 0: print('multi krum is ', multi_k)\n",
    "            agg_grads, krum_candidate = multi_krum(malicious_grads, n_attacker, multi_k=multi_k, verbose=True)\n",
    "        \n",
    "        elif aggregation == 'bulyan':\n",
    "            agg_grads, krum_candidate = bulyan(malicious_grads, n_attacker)\n",
    "            \n",
    "        start_idx=0\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num % 10 == 0:\n",
    "            print('%s: at %s at_frac %.1f n_at %d n_mal_sel %d e %d fed_model val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, at_fraction, n_attacker, np.sum(krum_candidate < n_attacker), epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our second AGR-agnostic attack - Min-Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def our_attack_score(all_updates, model_re, n_attackers, dev_type='unit_vec'):\n",
    "\n",
    "    if dev_type == 'unit_vec':\n",
    "        deviation = model_re / torch.norm(model_re)  # unit vector, dir opp to good dir\n",
    "    elif dev_type == 'sign':\n",
    "        deviation = torch.sign(model_re)\n",
    "    elif dev_type == 'std':\n",
    "        deviation = torch.std(all_updates, 0)\n",
    "    \n",
    "    lamda = torch.Tensor([50.0]).float().cuda()\n",
    "    # print(lamda)\n",
    "    threshold_diff = 1e-5\n",
    "    lamda_fail = lamda\n",
    "    lamda_succ = 0\n",
    "    \n",
    "    distances = []\n",
    "    for update in all_updates:\n",
    "        distance = torch.norm((all_updates - update), dim=1) ** 2\n",
    "        distances = distance[None, :] if not len(distances) else torch.cat((distances, distance[None, :]), 0)\n",
    "    \n",
    "    scores = torch.sum(distances, dim=1)\n",
    "    min_score = torch.min(scores)\n",
    "    del distances\n",
    "\n",
    "    while torch.abs(lamda_succ - lamda) > threshold_diff:\n",
    "        mal_update = (model_re - lamda * deviation)\n",
    "        distance = torch.norm((all_updates - mal_update), dim=1) ** 2\n",
    "        score = torch.sum(distance)\n",
    "        \n",
    "        if score <= min_score:\n",
    "            # print('successful lamda is ', lamda)\n",
    "            lamda_succ = lamda\n",
    "            lamda = lamda + lamda_fail / 2\n",
    "        else:\n",
    "            lamda = lamda - lamda_fail / 2\n",
    "\n",
    "        lamda_fail = lamda_fail / 2\n",
    "\n",
    "    mal_update = (model_re - lamda_succ * deviation)\n",
    "    return mal_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Initializing global model\n",
      "malicious grads shape  torch.Size([60, 848382])\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 11 e 0 fed_model val loss 4.0064 val acc 5.5086 best val_acc 5.508649 te_acc 5.982290\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 6 e 10 fed_model val loss 3.8430 val acc 5.9720 best val_acc 8.960564 te_acc 9.552615\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 9 e 20 fed_model val loss 3.8925 val acc 8.7083 best val_acc 14.698311 te_acc 15.856672\n",
      "bulyan: at min-sum at_frac 20.0 n_at 8 n_mal_sel 8 e 30 fed_model val loss 3.8842 val acc 17.4629 best val_acc 20.129736 te_acc 22.062912\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 10 e 40 fed_model val loss 3.7043 val acc 27.1983 best val_acc 29.787891 te_acc 33.332475\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 50 fed_model val loss 3.4163 val acc 32.4701 best val_acc 32.470140 te_acc 36.503810\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 9 e 60 fed_model val loss 3.2254 val acc 30.7712 best val_acc 32.549938 te_acc 36.403418\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 70 fed_model val loss 3.0844 val acc 32.9824 best val_acc 32.982393 te_acc 37.044378\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 80 fed_model val loss 2.9431 val acc 32.1149 best val_acc 33.376236 te_acc 37.456240\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 9 e 90 fed_model val loss 2.7986 val acc 34.2128 best val_acc 34.449650 te_acc 38.491042\n",
      "bulyan: at min-sum at_frac 20.0 n_at 10 n_mal_sel 10 e 100 fed_model val loss 2.7772 val acc 34.6324 best val_acc 34.653007 te_acc 38.666083\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 110 fed_model val loss 2.8569 val acc 32.7301 best val_acc 35.013386 te_acc 39.023888\n",
      "bulyan: at min-sum at_frac 20.0 n_at 10 n_mal_sel 10 e 120 fed_model val loss 2.8888 val acc 34.2772 best val_acc 35.286244 te_acc 39.162891\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 130 fed_model val loss 2.9198 val acc 33.9760 best val_acc 35.286244 te_acc 39.162891\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 140 fed_model val loss 2.9533 val acc 34.1433 best val_acc 35.286244 te_acc 39.162891\n",
      "bulyan: at min-sum at_frac 20.0 n_at 3 n_mal_sel 3 e 150 fed_model val loss 2.8588 val acc 35.0134 best val_acc 35.286244 te_acc 39.162891\n",
      "bulyan: at min-sum at_frac 20.0 n_at 10 n_mal_sel 10 e 160 fed_model val loss 2.7336 val acc 35.5926 best val_acc 35.592566 te_acc 39.806425\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 170 fed_model val loss 2.7453 val acc 35.2013 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 180 fed_model val loss 2.8141 val acc 34.6890 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 10 n_mal_sel 10 e 190 fed_model val loss 2.8290 val acc 34.6015 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 5 n_mal_sel 5 e 200 fed_model val loss 2.7684 val acc 35.2476 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 12 n_mal_sel 12 e 210 fed_model val loss 2.8070 val acc 34.6890 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 8 n_mal_sel 8 e 220 fed_model val loss 2.7746 val acc 34.7585 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 10 n_mal_sel 10 e 230 fed_model val loss 2.7352 val acc 34.6273 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 240 fed_model val loss 2.8141 val acc 33.4457 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 12 n_mal_sel 12 e 250 fed_model val loss 2.8666 val acc 32.9258 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 12 n_mal_sel 12 e 260 fed_model val loss 2.8786 val acc 33.4586 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 270 fed_model val loss 2.8018 val acc 34.4342 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 7 n_mal_sel 7 e 280 fed_model val loss 2.8853 val acc 34.6607 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 290 fed_model val loss 2.7432 val acc 35.0237 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 9 e 300 fed_model val loss 2.8807 val acc 34.4291 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 13 e 310 fed_model val loss 2.7405 val acc 34.7817 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 13 n_mal_sel 13 e 320 fed_model val loss 2.7974 val acc 34.2669 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 12 n_mal_sel 12 e 330 fed_model val loss 2.8483 val acc 34.1124 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 340 fed_model val loss 2.8917 val acc 34.1021 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 350 fed_model val loss 2.8328 val acc 34.9130 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 360 fed_model val loss 2.8326 val acc 34.3081 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 370 fed_model val loss 3.0100 val acc 34.4599 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 7 n_mal_sel 7 e 380 fed_model val loss 2.9755 val acc 33.4380 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 9 e 390 fed_model val loss 2.9439 val acc 34.1305 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 400 fed_model val loss 2.9983 val acc 34.1253 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 410 fed_model val loss 2.8953 val acc 33.5410 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 420 fed_model val loss 3.0111 val acc 34.2695 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 430 fed_model val loss 2.8570 val acc 34.9516 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 440 fed_model val loss 2.8930 val acc 35.0958 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 450 fed_model val loss 2.8760 val acc 35.5797 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 10 n_mal_sel 10 e 460 fed_model val loss 2.8523 val acc 35.7470 best val_acc 36.001853 te_acc 40.164230\n",
      "bulyan: at min-sum at_frac 20.0 n_at 10 n_mal_sel 10 e 470 fed_model val loss 2.8170 val acc 36.1923 best val_acc 36.192339 te_acc 40.326400\n",
      "bulyan: at min-sum at_frac 20.0 n_at 12 n_mal_sel 12 e 480 fed_model val loss 2.8491 val acc 36.2850 best val_acc 36.992895 te_acc 41.011120\n",
      "bulyan: at min-sum at_frac 20.0 n_at 13 n_mal_sel 13 e 490 fed_model val loss 2.7975 val acc 35.7676 best val_acc 36.992895 te_acc 41.011120\n",
      "bulyan: at min-sum at_frac 20.0 n_at 10 n_mal_sel 10 e 500 fed_model val loss 2.7981 val acc 36.5167 best val_acc 36.992895 te_acc 41.011120\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 510 fed_model val loss 2.8291 val acc 35.3660 best val_acc 36.992895 te_acc 41.011120\n",
      "bulyan: at min-sum at_frac 20.0 n_at 12 n_mal_sel 12 e 520 fed_model val loss 2.8772 val acc 36.5501 best val_acc 36.992895 te_acc 41.011120\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 530 fed_model val loss 2.8463 val acc 34.8100 best val_acc 36.992895 te_acc 41.011120\n",
      "bulyan: at min-sum at_frac 20.0 n_at 12 n_mal_sel 12 e 540 fed_model val loss 2.8071 val acc 35.6389 best val_acc 36.992895 te_acc 41.011120\n",
      "bulyan: at min-sum at_frac 20.0 n_at 12 n_mal_sel 12 e 550 fed_model val loss 2.8266 val acc 36.0714 best val_acc 36.992895 te_acc 41.011120\n",
      "bulyan: at min-sum at_frac 20.0 n_at 6 n_mal_sel 6 e 560 fed_model val loss 2.8032 val acc 35.9401 best val_acc 36.992895 te_acc 41.011120\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 9 e 570 fed_model val loss 2.8485 val acc 36.3442 best val_acc 36.992895 te_acc 41.011120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 580 fed_model val loss 2.8383 val acc 35.9684 best val_acc 36.992895 te_acc 41.011120\n",
      "bulyan: at min-sum at_frac 20.0 n_at 10 n_mal_sel 10 e 590 fed_model val loss 2.7175 val acc 36.5218 best val_acc 36.992895 te_acc 41.011120\n",
      "bulyan: at min-sum at_frac 20.0 n_at 10 n_mal_sel 10 e 600 fed_model val loss 2.6440 val acc 37.1293 best val_acc 37.636429 te_acc 41.675247\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 610 fed_model val loss 2.6275 val acc 37.0032 best val_acc 38.104922 te_acc 42.053645\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 620 fed_model val loss 2.6050 val acc 37.4382 best val_acc 38.321149 te_acc 42.365115\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 630 fed_model val loss 2.5988 val acc 38.4164 best val_acc 39.013591 te_acc 43.134782\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 640 fed_model val loss 2.5131 val acc 39.2067 best val_acc 39.706034 te_acc 43.518328\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 650 fed_model val loss 2.5579 val acc 38.8231 best val_acc 39.706034 te_acc 43.518328\n",
      "bulyan: at min-sum at_frac 20.0 n_at 7 n_mal_sel 7 e 660 fed_model val loss 2.5487 val acc 38.8540 best val_acc 39.706034 te_acc 43.518328\n",
      "bulyan: at min-sum at_frac 20.0 n_at 12 n_mal_sel 12 e 670 fed_model val loss 2.5148 val acc 38.9338 best val_acc 39.706034 te_acc 43.518328\n",
      "bulyan: at min-sum at_frac 20.0 n_at 13 n_mal_sel 13 e 680 fed_model val loss 2.5224 val acc 38.9261 best val_acc 39.752368 te_acc 43.948208\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 690 fed_model val loss 2.5159 val acc 39.2839 best val_acc 40.032949 te_acc 44.370367\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 700 fed_model val loss 2.5488 val acc 39.1088 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 710 fed_model val loss 2.5752 val acc 38.9235 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 12 n_mal_sel 12 e 720 fed_model val loss 2.5331 val acc 38.4962 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 10 n_mal_sel 10 e 730 fed_model val loss 2.5038 val acc 38.6455 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 740 fed_model val loss 2.4540 val acc 40.2183 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 9 e 750 fed_model val loss 2.4728 val acc 39.7292 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 13 n_mal_sel 13 e 760 fed_model val loss 2.4987 val acc 39.2350 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 770 fed_model val loss 2.4557 val acc 39.7652 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 12 n_mal_sel 12 e 780 fed_model val loss 2.5155 val acc 39.4589 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 790 fed_model val loss 2.4918 val acc 39.3843 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 7 n_mal_sel 7 e 800 fed_model val loss 2.4979 val acc 39.9866 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 7 n_mal_sel 7 e 810 fed_model val loss 2.5483 val acc 39.4769 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 820 fed_model val loss 2.5105 val acc 39.2324 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 12 n_mal_sel 12 e 830 fed_model val loss 2.5537 val acc 39.6108 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 13 n_mal_sel 13 e 840 fed_model val loss 2.5884 val acc 37.4717 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 8 n_mal_sel 8 e 850 fed_model val loss 2.5335 val acc 38.9544 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 860 fed_model val loss 2.5522 val acc 37.5592 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 870 fed_model val loss 2.5659 val acc 39.1217 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 880 fed_model val loss 2.5592 val acc 38.9003 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 12 n_mal_sel 12 e 890 fed_model val loss 2.6204 val acc 38.1899 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 900 fed_model val loss 2.6110 val acc 38.7253 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 910 fed_model val loss 2.6632 val acc 37.4717 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 920 fed_model val loss 2.6058 val acc 38.7510 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 10 n_mal_sel 10 e 930 fed_model val loss 2.5701 val acc 38.7098 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 13 n_mal_sel 13 e 940 fed_model val loss 2.6302 val acc 39.6288 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 950 fed_model val loss 2.5629 val acc 39.1809 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 960 fed_model val loss 2.5820 val acc 37.8578 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 13 n_mal_sel 13 e 970 fed_model val loss 2.6161 val acc 37.3430 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 980 fed_model val loss 2.6911 val acc 37.4743 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 990 fed_model val loss 2.6529 val acc 38.7510 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 10 n_mal_sel 10 e 1000 fed_model val loss 2.6091 val acc 39.0882 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1010 fed_model val loss 2.5794 val acc 39.1063 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 13 n_mal_sel 13 e 1020 fed_model val loss 2.6981 val acc 38.0663 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1030 fed_model val loss 2.6496 val acc 38.1718 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1040 fed_model val loss 2.6428 val acc 38.2233 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1050 fed_model val loss 2.6625 val acc 38.4293 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 9 e 1060 fed_model val loss 2.6896 val acc 37.2683 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 10 n_mal_sel 10 e 1070 fed_model val loss 2.6472 val acc 38.0689 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 1080 fed_model val loss 2.7554 val acc 37.8192 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 1090 fed_model val loss 2.6949 val acc 36.9517 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1100 fed_model val loss 2.6765 val acc 37.5669 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1110 fed_model val loss 2.7255 val acc 38.2156 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 1120 fed_model val loss 2.7334 val acc 36.4137 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1130 fed_model val loss 2.6736 val acc 37.9350 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 13 n_mal_sel 13 e 1140 fed_model val loss 2.6654 val acc 38.2722 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 13 n_mal_sel 13 e 1150 fed_model val loss 2.8000 val acc 37.6133 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 13 n_mal_sel 13 e 1160 fed_model val loss 2.6812 val acc 38.3907 best val_acc 41.363777 te_acc 44.964992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 1170 fed_model val loss 2.6820 val acc 37.7265 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1180 fed_model val loss 2.6707 val acc 38.1924 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1190 fed_model val loss 2.6051 val acc 38.8900 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 7 n_mal_sel 7 e 1200 fed_model val loss 2.7121 val acc 38.9827 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1210 fed_model val loss 2.6551 val acc 38.8488 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 9 e 1220 fed_model val loss 2.6871 val acc 38.4421 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 12 n_mal_sel 12 e 1230 fed_model val loss 2.7384 val acc 37.0547 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1240 fed_model val loss 2.6417 val acc 38.6172 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 9 e 1250 fed_model val loss 2.7148 val acc 37.7214 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1260 fed_model val loss 2.6659 val acc 39.6726 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 13 n_mal_sel 13 e 1270 fed_model val loss 2.6547 val acc 38.3881 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 8 n_mal_sel 8 e 1280 fed_model val loss 2.6984 val acc 37.6776 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 13 n_mal_sel 13 e 1290 fed_model val loss 2.7001 val acc 38.2105 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1300 fed_model val loss 2.7073 val acc 39.1706 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 13 n_mal_sel 13 e 1310 fed_model val loss 2.7195 val acc 38.7999 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 7 n_mal_sel 7 e 1320 fed_model val loss 2.7759 val acc 38.1410 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 13 n_mal_sel 13 e 1330 fed_model val loss 2.7900 val acc 38.9235 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1340 fed_model val loss 2.6730 val acc 38.9621 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 12 n_mal_sel 12 e 1350 fed_model val loss 2.6278 val acc 39.3585 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1360 fed_model val loss 2.7067 val acc 39.1114 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 1370 fed_model val loss 2.6893 val acc 38.6995 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 11 n_mal_sel 11 e 1380 fed_model val loss 2.7006 val acc 37.2735 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 10 n_mal_sel 10 e 1390 fed_model val loss 2.6550 val acc 39.7961 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1400 fed_model val loss 2.6868 val acc 38.8720 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 9 e 1410 fed_model val loss 2.7073 val acc 39.1371 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1420 fed_model val loss 2.6938 val acc 39.1166 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1430 fed_model val loss 2.7623 val acc 37.7857 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1440 fed_model val loss 2.6996 val acc 38.6172 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 8 n_mal_sel 8 e 1450 fed_model val loss 2.6577 val acc 37.9942 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 9 n_mal_sel 9 e 1460 fed_model val loss 2.7084 val acc 38.2465 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 13 n_mal_sel 13 e 1470 fed_model val loss 2.7502 val acc 38.3675 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 10 n_mal_sel 10 e 1480 fed_model val loss 2.7047 val acc 38.9570 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1490 fed_model val loss 2.7301 val acc 38.7073 best val_acc 41.363777 te_acc 44.964992\n",
      "bulyan: at min-sum at_frac 20.0 n_at 14 n_mal_sel 14 e 1500 fed_model val loss 2.7175 val acc 39.1835 best val_acc 41.363777 te_acc 44.964992\n"
     ]
    }
   ],
   "source": [
    "resume=0\n",
    "nepochs=1500\n",
    "gamma=.1\n",
    "fed_lr=0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()\n",
    "batch_size = 100\n",
    "schedule = [2000]\n",
    "\n",
    "aggregation = 'bulyan'\n",
    "at_type = 'min-sum'\n",
    "chkpt = './' + aggregation\n",
    "epoch_num = 0\n",
    "\n",
    "at_fractions = [20]\n",
    "\n",
    "for at_fraction in at_fractions:\n",
    "\n",
    "    fed_model = mnist_conv().cuda()\n",
    "    fed_model.apply(weights_init)\n",
    "    optimizer_fed = Adam(fed_model.parameters(), lr=fed_lr)\n",
    "\n",
    "    print('==> Initializing global model')\n",
    "    epoch_num = 0\n",
    "    best_global_acc=0\n",
    "    best_global_te_acc=0\n",
    "\n",
    "    while epoch_num <= nepochs:\n",
    "        user_grads = []\n",
    "\n",
    "        round_users = np.random.choice(3400, 60)\n",
    "        n_attacker = max(2, np.sum(round_users < (34*at_fraction)))\n",
    "        if n_attacker > 14: n_attacker = 14\n",
    "\n",
    "        attacker_count = 0\n",
    "        for i in round_users:\n",
    "            if i < (34*at_fraction) and attacker_count < n_attacker:\n",
    "                attacker_count += 1\n",
    "                continue\n",
    "\n",
    "            inputs = user_tr_data_tensors[i]\n",
    "            targets = user_tr_label_tensors[i]\n",
    "\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
    "\n",
    "            outputs = fed_model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            optimizer_fed.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "\n",
    "            param_grad=[]\n",
    "            for param in fed_model.parameters():\n",
    "                param_grad=param.grad.data.view(-1) if not len(param_grad) else torch.cat((param_grad,param.grad.view(-1)))\n",
    "\n",
    "            user_grads=param_grad[None,:] if len(user_grads)==0 else torch.cat((user_grads,param_grad[None,:]),0)    \n",
    "\n",
    "        malicious_grads = user_grads\n",
    "\n",
    "        if n_attacker > 0:\n",
    "            if at_type == 'fang':\n",
    "                agg_grads = torch.mean(malicious_grads, 0)\n",
    "                deviation = torch.sign(agg_grads)\n",
    "                mal_update = get_malicious_updates_fang(malicious_grads, agg_grads, deviation, n_attacker)\n",
    "            elif at_type == 'min-max':\n",
    "                agg_grads = torch.mean(malicious_grads, 0)\n",
    "                mal_update = our_attack_dist(malicious_grads, agg_grads, n_attacker, dev_type='sign')\n",
    "            elif at_type == 'min-sum':\n",
    "                agg_grads = torch.mean(malicious_grads, 0)\n",
    "                mal_update = our_attack_score(malicious_grads, agg_grads, n_attacker, dev_type='sign')\n",
    "                \n",
    "            mal_updates = torch.stack([mal_update] * n_attacker)\n",
    "            malicious_grads = torch.cat((mal_updates, user_grads), 0)\n",
    "            \n",
    "        if epoch_num == 0: print('malicious grads shape ', malicious_grads.shape)\n",
    "\n",
    "        if aggregation == 'mean':\n",
    "            agg_grads=torch.mean(malicious_grads,dim=0)\n",
    "            \n",
    "        elif aggregation=='krum' or aggregation=='mkrum':\n",
    "            multi_k = True if aggregation == 'mkrum' else False\n",
    "            if epoch_num == 0: print('multi krum is ', multi_k)\n",
    "            agg_grads, krum_candidate = multi_krum(malicious_grads, n_attacker, multi_k=multi_k, verbose=True)\n",
    "\n",
    "        elif aggregation == 'bulyan':\n",
    "            agg_grads, krum_candidate = bulyan(malicious_grads, n_attacker)\n",
    "            \n",
    "        start_idx=0\n",
    "\n",
    "        if epoch_num in schedule:\n",
    "            for param_group in optimizer_fed.param_groups:\n",
    "                param_group['lr'] *= gamma\n",
    "                print('New learnin rate ', param_group['lr'])\n",
    "\n",
    "        optimizer_fed.zero_grad()\n",
    "\n",
    "        model_grads=[]\n",
    "\n",
    "        for i, param in enumerate(fed_model.parameters()):\n",
    "            param_=agg_grads[start_idx:start_idx+len(param.data.view(-1))].reshape(param.data.shape)\n",
    "            start_idx=start_idx+len(param.data.view(-1))\n",
    "            param_=param_.cuda()\n",
    "            model_grads.append(param_)\n",
    "\n",
    "        optimizer_fed.step(model_grads)\n",
    "\n",
    "        val_loss, val_acc = test(val_data_tensor,val_label_tensor,fed_model,criterion,use_cuda)\n",
    "        te_loss, te_acc = test(te_data_tensor,te_label_tensor, fed_model, criterion, use_cuda)\n",
    "\n",
    "        is_best = best_global_acc < val_acc\n",
    "\n",
    "        best_global_acc = max(best_global_acc, val_acc)\n",
    "\n",
    "        if is_best:\n",
    "            best_global_te_acc = te_acc\n",
    "\n",
    "        if epoch_num % 10 == 0:\n",
    "            print('%s: at %s at_frac %.1f n_at %d n_mal_sel %d e %d fed_model val loss %.4f val acc %.4f best val_acc %f te_acc %f'%(aggregation, at_type, at_fraction, n_attacker, np.sum(krum_candidate < n_attacker), epoch_num, val_loss, val_acc, best_global_acc,best_global_te_acc))\n",
    "\n",
    "        epoch_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
